{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EEG_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3DHsI4K3up6"
      },
      "source": [
        "### EEGNet() w/PyTorch\n",
        "# Utsav Dutta, Medical Intelligence and Language Engineering Lab\n",
        "# IISc Bangalore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9g4D8CqCfwY"
      },
      "source": [
        "# Import relevant PyTorch libraries\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nefnnEyPe-C4"
      },
      "source": [
        "## Define a Dataset class module\n",
        "\n",
        "'''\n",
        "  - Root: Define root folder containing data in the form of the following:\n",
        "  /Class1\n",
        "    -S1\n",
        "    -S2\n",
        "    -S3..\n",
        "  /Class2\n",
        "    -S1\n",
        "    -S2\n",
        "    -S3..\n",
        "  where each class contains the same subjects.\n",
        "\n",
        "  - Index Map: \n",
        "    Mapping function from integer (0 to N), to [class,subject] mapping. \n",
        "    The helper function 'return_index' returns this mapping as a dictionary\n",
        "\n",
        "  - __getitem__:\n",
        "    Lazy load file when called for. Maps index to [class,subject] to build path.\n",
        "    Epoching of data is done WITHIN getitem and returns a tuple of sizes:\n",
        "    X -> [N_epochs,Channels,Times], Y -> [N_epochs, Labels]\n",
        "    \n",
        "    We define a custom_collate function to concatenate getitem calls instead of\n",
        "    stacking on first dimension as done by PyTorch's default mechanism.\n",
        "\n",
        "'''\n",
        "class EEGDataset(Dataset):\n",
        "\n",
        "  # Define self variables\n",
        "  def __init__(self,root = '/content/drive/MyDrive/med_data/'):\n",
        "    \n",
        "    self.root = root\n",
        "    self.index_map = {}\n",
        "    self.index_map_out = {}\n",
        "\n",
        "    # Create index map for __getitem__\n",
        "\n",
        "    index = 0\n",
        "    for state in os.listdir(self.root):\n",
        "      for path in os.listdir(self.root + state + '/'):\n",
        "\n",
        "        self.index_map[index] = (state,path)\n",
        "        self.index_map_out[index] = (state,path[:3])\n",
        "\n",
        "        index = index + 1\n",
        "    \n",
        "    self.length = index\n",
        "    # For eg, self.index_map[0] = (state,path)\n",
        " \n",
        "  # Define len method\n",
        "  def __len__(self):\n",
        "    \n",
        "    return self.length\n",
        "\n",
        "  # Define get_item method\n",
        "  def __getitem__(self,index):\n",
        "\n",
        "    state,path = self.index_map[index]\n",
        "    combined_path = self.root + state + '/' + path\n",
        "\n",
        "    # Load data into __getitem__\n",
        "    data = np.loadtxt(combined_path).T\n",
        "    \n",
        "    # Epoch and stack data\n",
        "    arr = []\n",
        "\n",
        "    n_seconds = 1\n",
        "    for start in range(0,data.shape[1],128*n_seconds):\n",
        "    \n",
        "      if start + 128*n_seconds < data.shape[1]:\n",
        "        arr.append(data[:,start:start + 128*n_seconds])\n",
        "\n",
        "    # Convert to array, dimensions [n_samples,channels,time]\n",
        "    X = np.array(arr)\n",
        "    Y = [(state,path[:3])]*X.shape[0]\n",
        "\n",
        "    sample = (torch.from_numpy(X),Y)\n",
        "\n",
        "    return sample\n",
        "\n",
        "  # Helper function to return indexes\n",
        "  def return_index(self):\n",
        "\n",
        "    return self.index_map_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr886X8P9zLB"
      },
      "source": [
        "subjects = [subject for state,subject in EEGDataset().return_index().values()]\n",
        "states = [state for state,subject in EEGDataset().return_index().values()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wquIGm-rxFgY"
      },
      "source": [
        "from torch.utils.data.sampler import Sampler\n",
        "import random\n",
        "\n",
        "## Create Custom Train Test Samplers\n",
        "\n",
        "'''\n",
        "\n",
        "  For EEG data, we create a custom train,test sampler which takes indices \n",
        "  corresponding to only one subject as test, and rest as train. The samplers are\n",
        "  then used to train on all subjects barring one.\n",
        "  The samplers retain indices corresponding to the values in index_map\n",
        "\n",
        "'''\n",
        "\n",
        "def create_samplers(dataset,leave_out_subject):\n",
        "\n",
        "  # Create a sampler over training indices, based on index values\n",
        "\n",
        "  class TrainSampler(Sampler):\n",
        "\n",
        "    def __init__(self,dataset,batch_size,leave_out_subject = leave_out_subject):\n",
        "\n",
        "      self.indexes = dataset.return_index()\n",
        "      self.train_indices = [key for key,value in self.indexes.items() if value[1] != leave_out_subject]\n",
        "    \n",
        "    def __iter__(self):\n",
        "      random.shuffle(self.train_indices)\n",
        "      \n",
        "      return iter(self.train_indices)\n",
        "    \n",
        "    def __len__(self):\n",
        "\n",
        "      return len(self.train_indices)\n",
        "  \n",
        "  # Create a sampler over test indices, based on index values\n",
        "\n",
        "  class TestSampler(Sampler):\n",
        "\n",
        "    def __init__(self,dataset,batch_size,leave_out_subject = leave_out_subject):\n",
        "\n",
        "      self.indexes = dataset.return_index()\n",
        "      self.test_indices = [key for key,value in self.indexes.items() if value[1] == leave_out_subject]\n",
        "    \n",
        "    def __iter__(self):\n",
        "      random.shuffle(self.test_indices)\n",
        "      \n",
        "      return iter(self.test_indices)\n",
        "    \n",
        "    def __len__(self):\n",
        "\n",
        "      return len(self.test_indices)\n",
        "  \n",
        "  return TrainSampler(dataset,leave_out_subject),TestSampler(dataset,leave_out_subject)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8r-Ocr2FIBH"
      },
      "source": [
        "# Custom Collate Function, stacks batches by concatenating along batch_dimension directly\n",
        "\n",
        "def custom_collate(batch):\n",
        "\n",
        "  X = [sample[0] for sample in batch]\n",
        "  Y = [sample[1] for sample in batch]\n",
        "  X = np.concatenate(X,axis = 0)\n",
        "  Y = np.concatenate(Y)\n",
        "\n",
        "  return torch.from_numpy(X),Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptmz4EnNdqcx"
      },
      "source": [
        "## First CONV Block - Temporal\n",
        "'''\n",
        "  Takes multivariate time series of the form [Channels,Timestamps] \n",
        "  Applies channelwise convolution to each time series, with n_filters = 10,\n",
        "  for each time series, given output of [Channels, n_filters, Timestamps_new]\n",
        "\n",
        "  Things to check : Number of Filters, Length fo Filter, LeakyReLU\n",
        "'''\n",
        "\n",
        "class Multiple1DTemporalBlock(nn.Module):\n",
        "\n",
        "  def __init__(self, channels = 61, conv_channels = 10, kernel_size = 60):\n",
        "    super().__init__()\n",
        "\n",
        "    self.channels = channels\n",
        "    self.Conv1DLayers = nn.ModuleList()\n",
        "\n",
        "    # Create a Conv1D filter for each time series\n",
        "\n",
        "    for channel in range(self.channels):\n",
        "\n",
        "      self.Conv1DLayers.append(\n",
        "          nn.Conv1d(in_channels = 1, \n",
        "                    out_channels = conv_channels, \n",
        "                    kernel_size = kernel_size,\n",
        "                    stride = 1,\n",
        "                    padding = 1)\n",
        "          )\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    out = []\n",
        "\n",
        "    for channel in range(self.channels):\n",
        "      \n",
        "      x_channel = x[:,[channel],:]\n",
        "      out.append(self.Conv1DLayers[channel](x_channel))\n",
        "    \n",
        "    # Stack on new dimension, output is 4D matrix\n",
        "    out = torch.stack(out, dim = 1)\n",
        "\n",
        "    # Pass through ReLU\n",
        "    out = F.leaky_relu(out,0.01)\n",
        "\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gh-xi8w6cw1v"
      },
      "source": [
        "## Second CONV Block - Spatial\n",
        "\n",
        "'''\n",
        "  Input from previous CONV block is of the form [Channels,Filters,Timestamps] \n",
        "  We wish to now compute filters to derive spatial features across channels.\n",
        "  This data can then be fed through further convolutions or into an LSTM.\n",
        "\n",
        "  We create a new 'channels' dimension, as required by pytorch and pass in \n",
        "  kernels of the shape (61,10,1) which are passed along the time axis (455).\n",
        "  We pass n_filters = 15 kernels like so, and squeeze the output back to\n",
        "  [Filters, Timestamps]\n",
        "\n",
        "'''\n",
        "\n",
        "class SpatialConvBlock(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # We use a conv1d filter and each convolution\n",
        "    # is on the entire spatial dimension at time t.\n",
        "    \n",
        "    self.conv1 = nn.Conv1d(\n",
        "        in_channels = 1, out_channels = 5, kernel_size = (61,10,1)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    # Perform unsqueeze and squeeze to convert to requisite dimensions\n",
        "\n",
        "    # [None,1,61,10,455]\n",
        "    x = torch.unsqueeze(x, dim = 1)\n",
        "\n",
        "    # [None,15,1,1,455]\n",
        "    x = self.conv1(x)\n",
        "    x = F.leaky_relu(x,0.01)\n",
        "\n",
        "    x = torch.squeeze(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Boff-NLYqYzA"
      },
      "source": [
        "## Linear Layer\n",
        "\n",
        "'''\n",
        "  Create fully connected layers.\n",
        "  Variable number of layers and sizes.\n",
        "  Input dimensions -> [batch, channels, steps]\n",
        "\n",
        "'''\n",
        "class LinearLayers(nn.Module):\n",
        "\n",
        "  def __init__(self,layer_sizes):\n",
        "    super().__init__()\n",
        "\n",
        "    self.num_layers = len(layer_sizes)\n",
        "\n",
        "    self.layerlist = nn.ModuleList()\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "\n",
        "      self.layerlist.append(nn.LazyLinear(layer_sizes[i]))\n",
        "    \n",
        "    self.fc = nn.LazyLinear(2)\n",
        "  \n",
        "  def forward(self,x):\n",
        "\n",
        "    x = x.view(x.shape[0],-1)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "\n",
        "      x = self.layerlist[i](x)\n",
        "      x = F.leaky_relu(x, 0.01)\n",
        "\n",
        "    x = self.fc(x)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH7G8fvay_zw"
      },
      "source": [
        "## Combine all models into a pipeline\n",
        "\n",
        "class EEGModel(nn.Module):\n",
        "\n",
        "  def __init__(self) :\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv_temp = Multiple1DTemporalBlock()\n",
        "    self.conv_spat = SpatialConvBlock()\n",
        "    self.linear_model = LinearLayers([1024,512])\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    x = self.conv_temp(x)\n",
        "\n",
        "    x = self.conv_spat(x)\n",
        "\n",
        "    x = self.linear_model(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VITXXuxhJ0Tn"
      },
      "source": [
        "## Helper Function for visualizing gradient flow\n",
        "# Use for debugging inside train loop\n",
        "\n",
        "from matplotlib.lines import Line2D\n",
        "\n",
        "def plot_grad_flow(named_parameters):\n",
        "\n",
        "    '''\n",
        "      Plots the gradients flowing through different layers in the net during training.\n",
        "      Can be used for checking for possible gradient vanishing / exploding problems.\n",
        "      \n",
        "      Usage: Plug this function in Trainer class after loss.backwards() as \n",
        "      \"plot_grad_flow(self.model.named_parameters())\" to visualize the gradient flow\n",
        "    '''\n",
        "\n",
        "    ave_grads = []\n",
        "    max_grads= []\n",
        "    layers = []\n",
        "\n",
        "    for n, p in named_parameters:\n",
        "\n",
        "        if(p.requires_grad) and (\"bias\" not in n):\n",
        "\n",
        "            layers.append(n)\n",
        "            ave_grads.append(p.grad.abs().mean())\n",
        "            max_grads.append(p.grad.abs().max())\n",
        "\n",
        "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
        "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
        "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
        "\n",
        "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
        "    plt.xlim(left=0, right=len(ave_grads))\n",
        "    plt.ylim(bottom = -0.001, top=0.02) # zoom in on the lower gradient regions\n",
        "    plt.xlabel(\"Layers\")\n",
        "    plt.ylabel(\"average gradient\")\n",
        "    plt.title(\"Gradient flow\")\n",
        "    plt.grid(True)\n",
        "    \n",
        "    plt.legend([Line2D([0], [0], color=\"c\", lw=4),\n",
        "                Line2D([0], [0], color=\"b\", lw=4),\n",
        "                Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyJftRVBxRw7"
      },
      "source": [
        "def train_model(model,optimizer,subject_id,dataset = EEGDataset(), epochs = 500, batch_size = 32):\n",
        "\n",
        "  '''\n",
        "    Defines the training block.\n",
        "\n",
        "    Inputs: \n",
        "      model for evaluation.\n",
        "      dataset.\n",
        "      epochs.\n",
        "      subject_id for test.\n",
        "      batch_size for sampler.\n",
        "\n",
        "    The model is first trained ONLY using trainloader. All subjects except for\n",
        "    the test subject\n",
        "    \n",
        "\n",
        "  '''\n",
        "\n",
        "  # Load stratified data samplers\n",
        "  train_sampler, test_sampler = create_samplers(dataset,subject_id)\n",
        "\n",
        "  # Load PyTorch dataloader objects  \n",
        "  trainloader = DataLoader(dataset, sampler = train_sampler, \n",
        "                           batch_size = batch_size, collate_fn = custom_collate)\n",
        "  testloader = DataLoader(dataset, sampler = test_sampler, \n",
        "                          batch_size = batch_size, collate_fn = custom_collate)\n",
        "\n",
        "  # Push model to GPU\n",
        "  device = 'cuda'\n",
        "\n",
        "  model = model.to(device = device)\n",
        "  dtype = torch.float32\n",
        "\n",
        "  # Define loss function\n",
        "  loss = nn.CrossEntropyLoss()\n",
        "\n",
        "  # Empty variable to collect loss over time\n",
        "  losses = []\n",
        "\n",
        "  ### Train Block\n",
        "\n",
        "  # Iterate over train loop\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    print('Epoch Number = ' + str(epoch))\n",
        "\n",
        "    for t,(x,y) in enumerate(trainloader):\n",
        "      \n",
        "      # model in training mode\n",
        "      model.train()\n",
        "\n",
        "      # Push data,targets to GPU\n",
        "      x = x.to(device = device, dtype = dtype)\n",
        "      x = x.float()\n",
        "\n",
        "      # Convert labels to LongTensor format\n",
        "      y = torch.LongTensor([1 if state == 'med' else 0 for state in y[:,0]])\n",
        "      y = y.to(device = device)\n",
        "\n",
        "      # Compute class scores (Nx2) array\n",
        "      scores = model(x)\n",
        "      \n",
        "      # Visualize confusion matrix, use detach() to extract PyTorch tensor as \n",
        "      # a numpy object\n",
        "      print(pd.crosstab(np.argmax(scores.cpu().detach().numpy(),axis = 1),\n",
        "                        y.cpu().detach().numpy(), rownames = ['pred'], \n",
        "                        colnames = ['true']))\n",
        "      \n",
        "      # Compute loss\n",
        "      # NOTE: Here, we use a weighted loss function to account for class imbalance\n",
        "      loss = nn.CrossEntropyLoss(weight = torch.FloatTensor([0.2 , 0.8]).cuda())(scores,y)\n",
        "\n",
        "      # Append loss of current iter to total losses\n",
        "      losses.append(loss)\n",
        "\n",
        "      # Set all grads to zero\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Compute all backward gradients\n",
        "      loss.backward()\n",
        "\n",
        "      # Visualize backwards gradients\n",
        "      plot_grad_flow(model.named_parameters())\n",
        "\n",
        "      # Compute new weights\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print iter loss\n",
        "      print('loss = ',round(loss.item(),2))\n",
        "      print('\\n')\n",
        "\n",
        "    # Visualize complete training loss\n",
        "    plt.plot(losses)\n",
        "    plt.show()\n",
        "\n",
        "  ## Test Loop\n",
        "\n",
        "  # Compute predictions over test data (loaded in batches due to memory constraint)\n",
        "  \n",
        "  accuracy = []\n",
        "\n",
        "  # Iterate over testloader\n",
        "  for t,(x_test,y_test) in enumerate(testloader):\n",
        "    \n",
        "    # Set model to eval mode\n",
        "    model.eval()\n",
        "\n",
        "    # Push data,targets to GPU\n",
        "    x_test = x_test.to(device = device, dtype = dtype)\n",
        "    x_test = x_test.float()\n",
        "\n",
        "    # Convert labels to LongTensor format\n",
        "    y_test = torch.LongTensor([1 if state == 'med' else 0 for state in y_test[:,0]])\n",
        "    y_test = y_test.to(device = device)\n",
        "\n",
        "    # Compute test scores\n",
        "    test_scores = model(x_test)\n",
        "    \n",
        "    # Append accuracy of epoch to accuracy list\n",
        "    accuracy.append(np.mean(np.argmax(scores.cpu().detach().numpy(),axis = 1) == y_test.cpu().detach().numpy()))\n",
        "\n",
        "  print(accuracy,np.mean(accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_HGAAH35iOA"
      },
      "source": [
        "## Helper function to run model\n",
        "\n",
        "  '''\n",
        "    Adam optimizer used by default. Specify changes to optimizer within function call\n",
        "    run_model takes in subject id of the form '101','102'...etc. to analyze \n",
        "    subject wise performance. The custom trainloaders take train data as all\n",
        "    subjects other than the subject id and test loaders take all data only\n",
        "    belonging to subject id.\n",
        "  '''\n",
        "\n",
        "def run_model(subject_id, batch_size = 4):\n",
        "\n",
        "  model = EEGModel()\n",
        "  optimizer = torch.optim.Adam(model.parameters())\n",
        "  batch_size = batch_size\n",
        "\n",
        "  train_model(model,optimizer,subject_id,batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngcJ9kNxZGr2"
      },
      "source": [
        "subject_id = '101'\n",
        "model = EEGModel()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "batch_size = 4\n",
        "\n",
        "run_model(subject_id,batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}